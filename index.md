---
layout: single
author_profile: true
title: "About Me"
---

I am a Researcher at the HCI Lab, Nazarbayev University, supervised by [Minho Lee](https://scholar.google.com/citations?user=ipi5AVsAAAAJ). I develop **controllable diffusion models** for medical image synthesis with clinical validation.

<div class="notice--info">
  <strong>Status:</strong> I am seeking PhD positions for Fall 2027.
</div>

## Research

My research focuses on **controllable generation for medical imaging**, specifically developing latent diffusion models that generate realistic medical images conditioned on clinical attributes (text descriptions, anatomical coordinates, segmentation masks). This work addresses critical data scarcity problems in medical AI.

**Current interests:** Multi-modal conditioning in diffusion models, downstream task validation for medical AI, semantic alignment in latent space, and synthetic data generation for rare pathologies.

## Publications & Preprints

**Latent-Aligned Diffusion for Controllable Chest X-ray Synthesis** *Computerized Medical Imaging and Graphics (CMIG), 2025 — Second Author, Under Review* We propose a latent diffusion model with semantic alignment mechanisms for generating chest X-rays conditioned on text prompts, spatial coordinates, and segmentation masks. Validated through radiologist evaluation.  
[Paper (Coming soon)](#){: .btn .btn--primary}

**DenseDiff: Virtual Digital Subtraction of Dense Tissue via Conditional Latent Diffusion** *In preparation for MICCAI 2026* A conditional diffusion model for computationally removing dense tissue from mammograms to improve lesion visibility. We validate the approach on downstream detection tasks.  
[Code (Coming soon)](#){: .btn .btn--light}

**Controllable Mammogram Synthesis using Multi-Input Latent Diffusion** *Work in progress* Extending controllable synthesis approaches to mammography with conditioning on clinical findings, BI-RADS categories, and anatomical landmarks.

## Open Source

**[controllable-medical-diffusion](https://github.com/Vadim-ATL)** (Coming soon)  
Clean PyTorch implementation of multi-conditional latent diffusion for medical imaging. Includes training scripts and pretrained weights.  
`PyTorch` `Diffusion Models` `Medical Imaging`

**[BloodMNIST-DDPM](https://github.com/Vadim-ATL/BloodMNIST-DDPM)** <span style="color:#28a745">⭐ Featured</span>  
Diffusion model for synthesizing realistic blood cell microscopy images. Generates 8 cell types with clinically accurate morphology.  
`Medical Imaging` `DDPM` `Hematology`

## Background

M.Sc. in Electrical & Computer Engineering from **Nazarbayev University** (2024, GPA 3.21/4.0). I also completed an academic exchange at **Brno University of Technology**, Czech Republic.

I have hands-on experience training large-scale generative models on local compute infrastructure (2× RTX 5090 GPUs), implementing diffusion models from scratch, and conducting medical imaging research with clinical validation.

**Languages:** Russian (native), English (IELTS 7.0), Czech (B2), Kazakh (B2), German (A1).

## PhD Applications

I am seeking PhD positions starting **Fall 2027** in generative modeling, diffusion models, and medical AI. Primary interests include European and Korean institutions with strong computer vision and medical imaging groups.