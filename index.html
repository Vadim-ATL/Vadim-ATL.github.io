<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Vadim Atlassov - Research in Generative Models & Medical AI</title>
    <meta name="description" content="Researcher working on Controllable Diffusion Models for Medical Image Synthesis at Nazarbayev University">
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 800px;
            margin: 0 auto;
            padding: 40px 20px;
            background: #fff;
        }
        h1 { 
            font-size: 32px; 
            margin-bottom: 10px; 
            font-weight: 600;
            color: #1a1a1a;
        }
        h2 { 
            font-size: 24px; 
            margin: 40px 0 20px 0; 
            font-weight: 600; 
            border-bottom: 2px solid #eee; 
            padding-bottom: 8px;
            color: #1a1a1a;
        }
        h3 { 
            font-size: 18px; 
            margin: 20px 0 10px 0; 
            font-weight: 600;
            color: #1a1a1a;
        }
        p { margin-bottom: 15px; }
        a { 
            color: #0066cc; 
            text-decoration: none;
            transition: color 0.2s;
        }
        a:hover { 
            color: #0052a3;
            text-decoration: underline; 
        }
        .contact { 
            margin: 20px 0; 
            font-size: 15px;
        }
        .contact a { 
            margin-right: 20px;
            display: inline-block;
            margin-bottom: 8px;
        }
        .paper { 
            margin-bottom: 25px; 
            padding: 15px; 
            background: #f9f9f9; 
            border-left: 3px solid #0066cc;
            border-radius: 4px;
        }
        .paper-title { 
            font-weight: 600; 
            font-size: 16px; 
            margin-bottom: 5px;
            color: #1a1a1a;
        }
        .paper-venue { 
            font-style: italic; 
            color: #666; 
            font-size: 14px; 
            margin-bottom: 8px;
        }
        .paper-description {
            font-size: 14px;
            margin: 8px 0;
            color: #444;
        }
        .paper-links { margin-top: 8px; }
        .paper-links a { 
            margin-right: 15px; 
            font-size: 14px;
            color: #0066cc;
        }
        .project { 
            margin-bottom: 20px;
            padding: 12px;
            background: #fafafa;
            border-radius: 4px;
        }
        .project-title { 
            font-weight: 600; 
            font-size: 16px;
            margin-bottom: 5px;
        }
        .project-description {
            font-size: 14px;
            margin: 5px 0 8px 0;
            color: #444;
        }
        .tag { 
            display: inline-block; 
            background: #e8e8e8; 
            padding: 3px 8px; 
            border-radius: 3px; 
            font-size: 13px; 
            margin-right: 5px; 
            margin-top: 5px;
            color: #555;
        }
        .bio { 
            font-size: 16px; 
            line-height: 1.7; 
            margin-bottom: 20px;
            color: #444;
        }
        .status {
            display: inline-block;
            background: #e3f2fd;
            color: #1565c0;
            padding: 4px 10px;
            border-radius: 4px;
            font-size: 13px;
            font-weight: 500;
            margin-bottom: 15px;
        }
        @media (max-width: 600px) {
            body { padding: 20px 15px; }
            h1 { font-size: 28px; }
            h2 { font-size: 22px; }
            .contact a { display: block; margin-bottom: 10px; }
        }
    </style>
</head>
<body>
    <h1>Vadim Atlassov</h1>
    <p class="bio">
        Researcher at HCI Lab, Nazarbayev University, supervised by <a href="https://scholar.google.com/citations?user=YOUR_ADVISOR_ID" target="_blank">Minho Lee</a>. I develop controllable diffusion models for medical image synthesis with clinical validation.
    </p>
    
    <div class="contact">
        <a href="mailto:vadim.atlassov@nu.edu.kz">Email</a>
        <a href="https://github.com/Vadim-ATL" target="_blank">GitHub</a>
        <a href="https://scholar.google.com/" target="_blank">Google Scholar</a>
        <!-- <a href="cv.pdf">CV (PDF)</a> -->
    </div>

    <div class="status">ðŸŽ“ Seeking PhD positions for Fall 2027</div>

    <h2>Research</h2>
    <p>
        My research focuses on <strong>controllable generation for medical imaging</strong>, specifically developing latent diffusion models that generate realistic medical images conditioned on clinical attributes (text descriptions, anatomical coordinates, segmentation masks). This work addresses critical data scarcity problems in medical AI, enabling better diagnostic models through synthetic training data.
    </p>
    <p>
        <strong>Current interests:</strong> Multi-modal conditioning in diffusion models, downstream task validation for medical AI, semantic alignment in latent space, synthetic data generation for rare pathologies.
    </p>

    <h2>Publications & Preprints</h2>

    <div class="paper">
        <div class="paper-title">Latent-Aligned Diffusion for Controllable Chest X-ray Synthesis</div>
        <div class="paper-venue">Computerized Medical Imaging and Graphics (CMIG), 2025 â€” Second Author, Under Review</div>
        <p class="paper-description">
            We propose a latent diffusion model with semantic alignment mechanisms for generating chest X-rays conditioned on text prompts, spatial coordinates, and segmentation masks. The model achieves state-of-the-art controllability while maintaining clinical realism, validated through radiologist evaluation and downstream classification tasks.
        </p>
        <div class="paper-links">
            <a href="#" target="_blank">Paper (arXiv - coming soon)</a>
            <!-- <a href="#" target="_blank">Code</a> -->
        </div>
    </div>

    <div class="paper">
        <div class="paper-title">DenseDiff: Virtual Digital Subtraction of Dense Tissue via Conditional Latent Diffusion</div>
        <div class="paper-venue">In preparation for MICCAI 2026</div>
        <p class="paper-description">
            A conditional diffusion model for computationally removing dense tissue from mammograms to improve lesion visibility. We validate the approach on downstream detection tasks, showing improved sensitivity for mass detection in dense breast tissue.
        </p>
        <div class="paper-links">
            <a href="#" target="_blank">Code (coming soon)</a>
        </div>
    </div>

    <div class="paper">
        <div class="paper-title">Controllable Mammogram Synthesis using Multi-Input Latent Diffusion</div>
        <div class="paper-venue">Work in progress</div>
        <p class="paper-description">
            Extending controllable synthesis approaches to mammography with conditioning on clinical findings, BI-RADS categories, and anatomical landmarks. Focus on generating realistic synthetic data for training screening algorithms.
        </p>
    </div>

    <h2>Open Source</h2>

    <div class="project">
        <div class="project-title">
            <a href="https://github.com/Vadim-ATL" target="_blank">controllable-medical-diffusion</a> (coming soon)
        </div>
        <p class="project-description">
            Clean PyTorch implementation of multi-conditional latent diffusion for medical imaging. Includes training scripts, inference pipelines, and pretrained weights for chest X-ray generation with text, coordinate, and mask conditioning.
        </p>
        <div>
            <span class="tag">PyTorch</span>
            <span class="tag">Diffusion Models</span>
            <span class="tag">Medical Imaging</span>
            <span class="tag">Multi-modal</span>
        </div>
    </div>

    <div class="project">
        <div class="project-title">
            <a href="https://github.com/Vadim-ATL" target="_blank">ddpm-from-scratch</a> (planned)
        </div>
        <p class="project-description">
            Minimal DDPM implementation in ~300 lines of PyTorch for educational purposes. Clear, commented code demonstrating the core mechanics of denoising diffusion probabilistic models without library abstractions.
        </p>
        <div>
            <span class="tag">PyTorch</span>
            <span class="tag">Tutorial</span>
            <span class="tag">Educational</span>
        </div>
    </div>

    <h2>Background</h2>
    <p>
        M.Sc. in Electrical & Computer Engineering from Nazarbayev University (2024, GPA 3.21/4.0). Academic exchange at Brno University of Technology, Czech Republic. Previously worked on CNN-based robotic vision systems with 6-DOF control and medical image segmentation. 
    </p>
    <p>
        I have hands-on experience training large-scale generative models on local compute infrastructure (2Ã— RTX 5090 GPUs), implementing diffusion models from scratch, and conducting medical imaging research with clinical validation. Proficient in PyTorch, Python, and standard ML tooling.
    </p>
    <p>
        <strong>Languages:</strong> Russian (native), English (IELTS 7.0), Czech (B2), Kazakh (B2), German (A1)
    </p>

    <h2>PhD Applications</h2>
    <p>
        I am seeking PhD positions starting Fall 2027 in generative modeling, diffusion models, and medical AI. Primary interests include European and Korean institutions with strong computer vision and medical imaging groups.
    </p>
    <p>
        <strong>Target institutions:</strong> KU Leuven, RWTH Aachen, LMU Munich, EPFL, ETH Zurich, POSTECH, Korea University, and other strong research groups in generative AI and medical imaging.
    </p>

    <footer style="margin-top: 60px; padding-top: 20px; border-top: 1px solid #eee; font-size: 14px; color: #666; text-align: center;">
        <p>Last updated: January 2026</p>
    </footer>

</body>
</html>